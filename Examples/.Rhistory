dictfiles<-paste0(root,'\\Dictionary')
datafiles<-paste0(root,'\\data')
dictfiles<-paste0(root,'\\Dictionary')
setwd(paste0(root,'\\scripts\\functions'))
source('prepro.txt')
source('prepro.R')
root<-setwd('C:\\Users\\admin\\Documents\\Sentiment Analysis')
library(fst)
setwd(paste0(root,'\\data'))
(paste0(root,'\\data')
paste0(root,'\\data')
paste0(root,'\\data')
root<-setwd('C:\\Users\\admin\\Documents\\Sentiment Analysis')
setwd(paste0(root,'\\data'))
read.fst<-'final_sentiment.fst'
fs<-read.fst('final_sentiment.fst')
View(fs)
library(tidytext)
install.packages('tidytext')
library(tidytext)
sentiments
text_df <- tibble(line = 1:4, text = fs$text)
library(dplyr)
text_df <- tibble(line = 1:4, text = fs$text)
text_df <- tibble( text = fs$text)
View(text_df)
text_df
text_df %>%
unnest_tokens(word, text)
View(text_df)
unnest_tokens(word, text)
text_df %>%
unnest_tokens(word, text)
text_df %>%
unnest_tokens( text)
unnest_tokens(text)
text_df %>%
unnest_tokens(word,fs$text)
View(text_df)
text_df <- tibble( text = as.character(fs$text))
text_df %>%
unnest_tokens(word,fs$text)
View(text_df)
text_df %>%
unnest_tokens(word,text)
View(text_df)
t<-text_df %>%
unnest_tokens(word,text)
View(t)
df_btw17_pdf <- readtext("QTA Julian/files/*.pdf",
docvarsfrom = "filenames",
docvarnames = c("polidoc_id", "year"),
sep = "_")
library(readtext)
df_btw17_pdf <- readtext("QTA Julian/files/*.pdf",
docvarsfrom = "filenames",
docvarnames = c("polidoc_id", "year"),
sep = "_")
files<-list.files("QTA Julian/files/")
df_btw17_pdf <- readtext(files,
docvarsfrom = "filenames",
docvarnames = c("polidoc_id", "year"),
sep = "_")
files
files<-list.files("QTA Julian/files")
files<-list.files("~/documents/QTA Julian/files")
files<-list.files("C:user/admin/documents/QTA Julian/files")
files<-list.files("C:(user/admin/documents/QTA Julian/files")
files<-list.files("C:/user/admin/documents/QTA Julian/files")
files<-list.files("C:/users/admin/documents/QTA Julian/files")
df_btw17_pdf <- readtext(files,
docvarsfrom = "filenames",
docvarnames = c("polidoc_id", "year"),
sep = "_")
files
df_btw17_pdf <- readtext(files,
docvarsfrom = "filenames",
docvarnames = c("polidoc_id", "year"))
files
df_btw17_pdf <- readtext(files)
df_btw17_pdf <- readtext("C:/users/admin/documents/QTA Julian/files/*.pdf",
docvarsfrom = "filenames",
docvarnames = c("polidoc_id", "year"),
sep = "_")
df_btw17_pdf <- readtext("C:/users/admin/documents/QTA Julian/files/*.pdf",
docvarsfrom = "filenames",
docvarnames = c("polidoc_id", "year"),
sep = "_")
df_btw17_pdf <- readtext("C:/users/admin/documents/QTA Julian/files/*.txt",
docvarsfrom = "filenames",
docvarnames = c("polidoc_id", "year"),
sep = "_")
df_btw17_pdf <- readtext("C:/users/admin/documents/QTA Julian/files/*.txt",
docvarsfrom = "filenames",
docvarnames = c("polidoc_id", "year"))
df_btw17_pdf <- readtext("C:/users/admin/documents/QTA Julian/files/*.txt")
View(df_btw17_pdf)
df_btw17_pdf <- readtext("C:/users/documents/QTA Julian/files/*.pdf",
docvarsfrom = "filenames",
docvarnames = c("polidoc_id", "year"),
sep = "_")
df_btw17_pdf <- readtext("C:/users/documents/QTA Julian/files/*.pdf",
docvarsfrom = "filenames",
docvarnames = c("polidoc_id", "year"),
sep = "_")
df_btw17_pdf <- readtext("C:/users/documents/QTA Julian/files/41223.000.2017.1.1.pdf",
docvarsfrom = "filenames",
docvarnames = c("polidoc_id", "year"),
sep = "_")
df_btw17_pdf <- readtext("C:/users/admin/documents/QTA Julian/files/41223.000.2017.1.1.pdf",
docvarsfrom = "filenames",
docvarnames = c("polidoc_id", "year"),
sep = "_")
df_btw17_pdf <- readtext("C:/users/admin/documents/QTA Julian/files/41223.000.2017.1.1.pdf")
View(df_btw17_pdf)
df <- readtext("C:/users/admin/documents/QTA Julian/files/41223.000.2017.1.1.pdf")
df$text
sp<-strsplit(df$text,'\r\n')
sp
setwd(paste0(root,'\\data'))
list.files(getwd())
l<-list.files(getwd())
l<-l[grepl(l,'.csv'),]
l<-l[grepl('.csv',l),]
l<-l[grepl('.csv',l)]
base<-list()
for(i in 1:length(l)){
base[i]<-read.csv(l[i],stringsAsFactors = F,row.names = F,header = T)
}
base<-list()
for(i in 1:length(l)){
base[i]<-read.csv(l[i],stringsAsFactors = F,header = T)
}
base<-list()
for(i in 1:length(l)){
base[[i]]<-read.csv(l[i],stringsAsFactors = F,header = T)
}
hessen<-base[[i]]
names(hessen)
intersect(names(base[[1]],base[[2]]))
intersect(names(base[[1]]),names(base[[2]]))
nom<-intersect(names(base[[1]]),names(base[[2]]))
b[,nom]
full<-c()
for(i in 1:length(base)){
b<-base[[i]]
nom<-intersect(names(base[[1]],names(b)))
c<-b[,nom]
full<-rbind(full,c)
}
full<-c()
for(i in 1:length(base)){
b<-base[[i]]
nom<-intersect(names(base[[1]]),names(b))
c<-b[,nom]
full<-rbind(full,c)
}
nom<-intersect(names(base[[1]]),names(b))
nom
c<-b[,nom]
full<-rbind(full,c)
full<-c()
for(i in 1:length(base)){
b<-base[[i]]
nom<-intersect(names(base[[1]]),names(b))
c<-b[,nom]
full<-rbind(full,c)
}
full<-c()
for(i in 1:length(base)){
b<-base[[i]]
nom<-intersect(names(base[[1]]),names(b))
c<-b[,nom]
full<-full[,nom]
full<-rbind(full,c)
}
root<-'C:\\Users\\admin\\Documents\\Sentiment Analysis'
setwd(root)
source('control.R')
s<-source('control.R')
s
s<-source('control.R')
setwd('C:\\Users\\admin\\Documents\\Sentiment Analysis\\scripts')
source('select.R')
source('1 select.R')
source('1 select.R')
select_tw(root)
import_tw(root)
import_tw<-function(dir,type='.csv'){
setwd(dir)
l<-list.files(getwd())
l<-l[grepl(filetype,l)]
base<-list()
for(i in 1:length(l)){
base[[i]]<-read.csv(l[i],stringsAsFactors = F,header = T)
}
full<-c()
for(i in 1:length(base)){
b<-base[[i]]
nom<-intersect(names(base[[1]]),names(b))
c<-b[,nom]
full<-full[,nom]
full<-rbind(full,c)
}
library(fst)
w<-full
return(w)
}
working<-import_tw(root)
source('1 select.R')
working<-import_tw(root)
source('1 select.R')
setwd('C:\\Users\\admin\\Documents\\Sentiment Analysis\\scripts')
s<-source('control.R')
root<-'C:\\Users\\admin\\Documents\\Sentiment Analysis\\scrips\\functions'
setwd(root)
s<-source('Select.R')
setwd('C:\\Users\\admin\\Documents\\Sentiment Analysis\\scripts\functions')
setwd('C:\\Users\\admin\\Documents\\Sentiment Analysis\\scripts\functions')
setwd('C:\\Users\\admin\\Documents\\Sentiment Analysis\\scripts\\functions')
source('select.R')
working<-import_tw(root)
fun<-paste0(root,'\\scripts\\functions')
dat<-paste0(root,'\\scripts\\data')
working<-import_tw(dat)
dat
dat<-paste0(root,'\\data')
working<-import_tw(dat)
dat
dat<-paste0(root,'\\data')
dat
root<-'C:\\Users\\admin\\Documents\\Sentiment Analysis\\'
dat<-paste0(root,'\\data')
root<-'C:\\Users\\admin\\Documents\\Sentiment Analysis\\'
dat<-paste0(root,'\\data')
dat
root<-'C:\\Users\\admin\\Documents\\Sentiment Analysis'
dat<-paste0(root,'\\data')
working<-import_tw(dat)
token8<-c('Cats4Congress',"efM73Kdy9kToACt7uHcaLbeXe","IixyRLlk35xHhjpJQIQht0L2NxxDPz0VgfRgkinfVzoihN0z6D","1049169595-pkEvtElgjpGMJtvVhxzOk0IKiqZ48XAAS5vd76O","5WBiBijTOErpBYfy88QUq9ZhampnXqqett1uR4bIliBaW")
token7<-c("Funtime with Tim","msxPc23rIC44dOItQM0SlfEFL","oE66FwqhLqA2k0EnRJPc2tFGJI8xSzx2VrI8vowuyqMTL9LLMN","1045689088253333504-C9QQ1vWGtcPp77mFQLhzt70rTXwjLx","GEEsdjAHL8dv8bBhecoh4F6t5DxuHcWk7iiC8bhhnrznz")
token6<-c('Potato Sandwich',"70p3BHkwthXDrsA7BGclkVuek","IXNy3NFmJNtG9ROCUuU1RGNMHvu6Fng5tYnY66gFV0Ho3fkKCW",
"1046334986654285824-bwEqAfeCkZ25X0TVIUDo67QrgktQYj",
"dvxHEjBnV33zMG7uXoBuMr2L55JMMjYvhKOca37xd2y6z")
token4<-c('hellobundestag',
'BRweN016Pbetc1Un6c4Sa4eSN',
'SomWdxCJgUAgsKNr1yekuCTaNoxBrKYYOvb1x0Lv2nXz8ByNwd',
'907615723790520320-YA5JzmHqOoQ9pYlhOna4W1JK1DtHgYb',
'SBwMJgPSfKwdosjqOfXuiASpPPdwSSSLb3TLfte9iyYG2')
token3<-c('smadavapp',
"d6LUV57bnfyXU7RakjZVA09Gs",
"7RYiKdYzMqAB26eVYD3zFgp6kX17smwtEfxLk7vqpt0IoaMYYi",
"2565146921-0PyFY0wX03CisSDwD9hvZzYzEPPSA1TZ6Usdm60",
"01CvMPcJ1tDQtVy8CUfT9w02rWs1O7mOwkj0uXON3Gj0T")
token2<-c('congresswatch_1','B8OBjpVKX6m6CEKnDG1OFFjCG','djD3yWujirTFA270o1QNR70WL0gnGekLkowxUd9nwHmgpHAOFb','907615723790520320-MZGftQ6BkQiahaZkLcmGVJ6dbpYhFAk','WKIjzoRgfULiaCt68lvzQpeRy2fyJKn73S9YRlm3gc6LM')
token1<-c('polyscythe',"c5v1oQhxjXJvWzS4jWC0PG5Xi","pbMNdVvl4R4hSushSUzVUxIlC4jY7VCr19J2pT24BWmrl1FpdH","907615723790520320-uCNOmBq7zT7v1AYprr5NRktPhOUXOb1","DZoSY3yawC9oW7Q3wxCj2RUcraC0ZsKGGeLqL8MZgowDZ")
token5<-c('app3232','cNg2vFw5BtscKHSYfFtrL5Flm2','dQkbBT7eS9NcV8mBgFlznOYE8AXt2mQNLXm5XJl3himp2QN8RD','1042415401811025921-n2tlln8kHtdbUE5q8AiTnWmq49S8ml',
'x4r4UvHly0AdeLTG7AbDGNbhbBQWNmEY9pLYaGDWHE65E')
tokenz<-rbind(token1,token2,token3,token4,token5,token6,token7,token8)
write.csv(tokenz,'tokens.csv')
tok<-read.csv('tokenz.csv')
fun<-paste0(root,'\\scripts\\functions')
setwd(paste0(fun,'\\key'))
)
setwd(paste0(fun,'\\key'))
paste0(fun,'\\key'
paste0(fun,'\\key')
paste0(fun,'\\key')
setwd(paste0(fun,'\\keys'))
setwd(paste0(fun,'\\keys'))
tok<-read.csv('tokenz.csv')
tok<-read.csv('tokens.csv')
setwd(paste0(fun,'\\keys'))
tok
View(tok)
tokenize_key<-function(i,tok){
create_token(app=tok[i,2],tok[i,3],tok[i,4],tok[i,5],tok[i,6],set_renv=F)
}
tokenize_key(3,tok)
library(rtweet)
tokenize_key(3,tok)
[i,2]
tok[i,2]
tok<-read.csv('tokens.csv',stringsAsFactors = F)
tokenize_key(3,tok)
setwd(dat)
d<-Sys.Date()
i<-1
i<-ifelse(i==nrow(tok),1,i+1)
i<-ifelse(i==nrow(tok),1,i+1)
i<-ifelse(i==nrow(tok),1,i+1)
i<-ifelse(i==nrow(tok),1,i+1)
i<-ifelse(i==nrow(tok),1,i+1)
i<-ifelse(i==nrow(tok),1,i+1)
i<-ifelse(i==nrow(tok),1,i+1)
i<-ifelse(i==nrow(tok),1,i+1)
i<-ifelse(i==nrow(tok),1,i+1)
i<-ifelse(i==nrow(tok),1,i+1)
i<-ifelse(i==nrow(tok),1,i+1)
i<-ifelse(i==nrow(tok),1,i+1)
i<-ifelse(i==nrow(tok),1,i+1)
i<-ifelse(i==nrow(tok),1,i+1)
i<-ifelse(i==nrow(tok),1,i+1)
i<-ifelse(i==nrow(tok),1,i+1)
source('2 Preprocessing.R')
script<-paste0(root,'\\scripts')
setwd(script)
source('2 Preprocessing.R')
knitr::opts_chunk$set(echo = TRUE)
hj_senti<-apply_senti(working,'hj',stemmed=T)
root<-'C:\\Users\\admin\\Dropbox\\Sentiment Analysis'
fun<-paste0(root,'\\scripts\\functions')
script<-paste0(root,'\\scripts')
docu<-paste0(root,'\\documentation')
docufiles<-paste0(root,'\\documentation\\files')
dat<-paste0(root,'\\data')
root
setwd(fun)
#source('unpack.R')
library(rtweet)
library(stringr)
library(ggplot2)
library(dplyr)
library(qdapRegex)
library(wordcloud)
library(utils)
toklink<-'https://www.dropbox.com/s/msxbxx0rc3898yq/tokens.csv?dl=1'
setwd(script)
source('0_Call.R')
input<-c('spdbt')
call_api(input,toklink=toklink)
setwd(script)
source('1_select.R')
## here we should specify
working<-import_tw(dat) #inp=input if your want a specific account, not all
setwd(fun)
source('tweetvariation.R')
working<-tweetvariation(working)
daytime<-ggplot(working, aes(x=as.POSIXct(hour, format="%H:%M:%S"),fill=source))
daytime +scale_x_datetime(labels = function(x) format(x, format = "%H:%M"))+
labs(x="Tageszeit", y="tweets", fill="GerÃ¤t")+
geom_histogram(binwidth = 3600)
setwd(script)
source('2_Preprocessing.R')
working$clean<-cleaner(working)
i<-17
print(cbind(working$text[i],working$clean[i]))
setwd(fun)
source('wfm.R')
d<-wfm(working)
set.seed(1234)
wordcloud(words = d$word, freq = d$freq, min.freq = 1,
max.words=100, random.order=F, rot.per=0.35,
colors=brewer.pal(8, "Dark2"))
working$clean<-cleaner(working,stem=T)
i<-17
print(cbind(working$text[i],working$clean[i]))
setwd(script)
source('3_Dictionary.R')
dict<-get_senti()
print(dict[sample(nrow(dict),10),])
res_senti<-apply_senti(working,'sentiws',stemmed=T)
rau_senti<-apply_senti(working,'rauh',stemmed=T)
hj_senti<-apply_senti(working,'hj',stemmed=T)
View(hj_senti)
rauhscore<-rau_senti$score
rauhpol<-rau_senti$pol
hjscore<-hj_senti$score
hjpol<-hj_senti$score
res<-cbind(res_senti,rauhscore,rauhpol,hjscore,hjpol)
cor(hjscore,rauhscore)
cor(hjscore,rauhscore,res_senti$score)
cor(res$score,res$hjscore,res$rauhscore)
names(res)
cor(res[,c(38,40,42)])
cor(res[,c(39,41,43)])
View(res)
setwd(examples)
tweet.data<- read.csv("tweet_data.csv")
examples<-paste0(root,'\\documentation\\files\\examples')
dat<-paste0(root,'\\data')
setwd(examples)
tweet.data<- read.csv("tweet_data.csv")
setwd(examples)
examples
root
examples<-paste0(root,'\\examples')
setwd(examples)
tweet.data<- read.csv("tweet_data.csv")
Main.model<- glmer.nb(reach~neg+pos+hashtag_count+URL_dummy+
(1|screen)+(1|party),
data=tweet.data, nAGQ=0)
library(lme4)
Main.model<- glmer.nb(reach~neg+pos+hashtag_count+URL_dummy+
(1|screen)+(1|party),
data=tweet.data, nAGQ=0)
Main.model<-readRDS("Main_model.rds")
saveRDS(Main.model, "Main_model.rds")
Main.model<-readRDS("Main_model.rds")
Main.model<-readRDS("Main_model.rds")
Plot.model<- glmer.nb(reach~neg+hashtag_count+URL_dummy+
(1|screen)+(1|party),
data=tweet.data, nAGQ=0)
saveRDS(Plot.model, "Plot_model.rds")
Plot.model<-readRDS("Plot_model.rds")
setwd(fun)
source('predictdata.R')
candidate.prediction<- predict.full(Plot.model, tweet.data,
c("gerdmannesafd", "markus_soeder", "atesguerpinar"),
c("AfD", "Union", "DIE LINKE"))
pred.curve<- ggplot(candidate.prediction, aes(x=neg, y=pred, col=screen))
pred.curve+geom_line(size=1)+
labs(x="Negativity", y="Reach", col="Screen Name")
pred.curve<- ggplot(candidate.prediction, aes(x=neg, y=pred, col=screen))
pred.curve+geom_line(size=1)+
labs(x="Negativity", y="Reach", col="Screen Name")
working[1:100,c(3,6)
write.csv(working[1:100,c(3,6)])
working[1:100,c(3,6)]
names(working)
write.csv(working[1:30,4])
setwd(root)
cor(res[,c(39,41,43)])
write.csv(working[1:30,4])
root
write.csv(working[1:30,4])
write.csv(working[1:30,4])
write.csv(working[1:30,4],''validate.csv')
write.csv(working[1:30,4],'validate.csv')
setwd(root)
write.csv(working[1:30,4],'validate.csv')
setwd(examples)
individual.data<- read.csv("secondary_data.csv")
individual.data<- individual.data[complete.cases(individual.data),]
aud.str<-ggplot(individual.data, aes(x=median_pos, y=var_pos, col=party, size=followers_count))
aud.str+geom_point(alpha=0.5)+
labs(x="Median Follower", y="Variance", col="Partei", size="Anzahl Follower")
setwd(examples)
individual.data<- read.csv("secondary_data.csv")
individual.data<- individual.data[complete.cases(individual.data),]
aud.str<-ggplot(individual.data, aes(x=median_pos, y=var_pos, col=party, size=followers_count))
aud.str+geom_point(alpha=0.5)+
labs(x="Median Follower", y="Variance", col="Partei", size="Anzahl Follower")
neg.model<- lm(neg.x~var_pos+median_pos+log(followers_count)+party-1, data=individual.data)
setwd(fun)
source('predictdata.R')
effect.var<- predict.secondary(neg.model, individual.data, by.var = T)
var.effect<- ggplot(effect.var, aes(x=var_pos, y=pred, col=party))
var.effect+geom_line()+
labs(x="Varianz", y="Negativity Incentive", col="Partei")
effect.med<- predict.secondary(neg.model, individual.data, by.var = F)
med.effect<- ggplot(effect.med, aes(x=median_pos, y=pred, col=party))
med.effect+geom_line()+
labs(x="Median", y="Negativity Incentive", col="Partei")
effect.med<- predict.secondary(neg.model, individual.data, by.var = F)
med.effect<- ggplot(effect.med, aes(x=median_pos, y=pred, col=party))
med.effect+geom_line()+
labs(x="Median", y="Negativity Incentive", col="Partei")
neg.model<- lm(neg.x~var_pos+median_pos+log(followers_count)+party-1, data=individual.data)
setwd(fun)
source('predictdata.R')
effect.var<- predict.secondary(neg.model, individual.data, by.var = T)
var.effect<- ggplot(effect.var, aes(x=var_pos, y=pred, col=party))
var.effect+geom_line()+
labs(x="Varianz", y="Negativity Incentive", col="Partei")
effect.med<- predict.secondary(neg.model, individual.data, by.var = F)
med.effect<- ggplot(effect.med, aes(x=median_pos, y=pred, col=party))
med.effect+geom_line()+
labs(x="Median", y="Negativity Incentive", col="Partei")
neg.model<- lm(neg.x~var_pos+median_pos+log(followers_count)+party-1, data=individual.data)
setwd(fun)
source('predictdata.R')
effect.var<- predict.secondary(neg.model, individual.data, by.var = T)
var.effect<- ggplot(effect.var, aes(x=var_pos, y=pred, col=party))
var.effect+geom_line()+
labs(x="Varianz", y="Negativity Incentive", col="Partei")
setwd(examples)
individual.data<- read.csv("secondary_data.csv")
individual.data<- individual.data[complete.cases(individual.data),]
aud.str<-ggplot(individual.data, aes(x=median_pos, y=var_pos, col=party, size=followers_count))
aud.str+geom_point(alpha=0.5)+
labs(x="Median Follower", y="Variance", col="Partei", size="Anzahl Follower")
neg.model<- lm(neg.x~var_pos+median_pos+log(followers_count)+party-1, data=individual.data)
setwd(fun)
source('predictdata.R')
my.colors<- c("cornflowerblue","deeppink","gold", "orange","green","red", "black")
effect.var<- predict.secondary(neg.model, individual.data, by.var = T)
var.effect<- ggplot(effect.var, aes(x=var_pos, y=pred, col=party))
var.effect+geom_line()+
labs(x="Varianz", y="Negativity Incentive", col="Partei")+  scale_color_manual(values = my.colors)
setwd(examples)
individual.data<- read.csv("secondary_data.csv")
individual.data<- individual.data[complete.cases(individual.data),]
my.colors<- c("cornflowerblue","deeppink","gold", "orange","green","red", "black")
aud.str<-ggplot(individual.data, aes(x=median_pos, y=var_pos, col=party, size=followers_count))
aud.str+geom_point(alpha=0.5)+
labs(x="Median Follower", y="Variance", col="Partei", size="Anzahl Follower")+  scale_color_manual(values = my.colors)
effect.med<- predict.secondary(neg.model, individual.data, by.var = F)
my.colors<- c("cornflowerblue","deeppink","gold", "orange","green","red", "black")
med.effect<- ggplot(effect.med, aes(x=median_pos, y=pred, col=party))
med.effect+geom_line()+
labs(x="Median", y="Negativity Incentive", col="Partei")+  scale_color_manual(values = my.colors)
timetrend<-ggplot(working, aes(x=day, col=type))
timetrend+geom_freqpoly(binwidth=2604800, size=1)+
labs(x="Monat", y="tweets", col="Art")
# binwidth: woche-> 604800, tag-> 86400, monat -> 2.6 mio
reaction<- ggplot(res[res$retweet_count>0,], aes(x=score, y=retweet_count, col=type))
reaction+geom_point(alpha=0.4)+
labs(x="Ton", y="Retweets", col="Art")
lastweek<- ggplot(res[res$day>"2019-02-15",], aes(x=day, y=score, col=type))
lastweek+geom_jitter()+
labs(x="Tag", y="Ton", col="Art")
